{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data is one crucial step in the deep learning pipeline. PyTorch makes it easy to write custom data loaders for your particular dataset. In this notebook, we're going to download and load cifar-10 dataset and return a torch \"tensor\" as the image and the label. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head over to [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset homepage and download the \"python\" version mentioned on the page. Extract the `tar.gz` archive in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 dataset is divided into 5 training batches and one test batch. In order to train effectively we need to use all the training data. The datasets themselves are stored in a \"pickle\" format so we have to \"unpickle\" them first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os \n",
    "import pickle \n",
    "\n",
    "def unpickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        Dict = pickle.load(f, encoding='bytes')\n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if we actually can load the data after the unpickling. For that we're going to load one the data batches and see if we can find the data and labels from it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Dic = unpickle(os.path.join('/home/akulshr','cifar-10-batches-py', 'data_batch_1'))\n",
    "print(Dic[b'data'].shape)\n",
    "print(len(Dic[b'labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the data is a numpy array of 1000x3072 which means that the data batch contains 10000 images of size 3072 (32x32x3). The labels are 1000x1 list in which the *i*th element corresponds to the correct label for the *i*th image. This is how data is in the other training batches. Whenever you've got a new dataset always try to load one or two images(or a data batch) like in this case to get a feel of how the data is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data like this can be tedious and time consuming. Let's write a helper function which will return the data and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(batch):\n",
    "    print (\"Loading batch:{}\".format(batch))\n",
    "    return unpickle(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little helper function will call our \"unpickling\" function to unpickle the data and return the unpicked data back to us.In datasets where there is only images, you can use `PIL.Image`. Armed with this let's write a dataloader for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoading in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloading in PyTorch is a two step process. First, you need define a custom class which is subclassed from a `data.Dataset` class in `torch.utils.data`. This class takes in arguments which tell PyTorch about the location of the dataset, any \"transforms\" that you need to make before the dataset is loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import the relevant modules. The `data` module which contains the useful functions for dataloading is contained in `torch.utils.data`. We also need a utility called `glob` to get all our batches in a list. The dataset is split into 5 different parts and we need to have them all together so we can use the entire training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.utils.data as data \n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Every dataloader in PyTorch needs this form. The class you write for a DataLoader contains two methods `__init__` and `__getitem__`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `__init__` method is where you define arguments telling the location of your dataset, transforms (if any). It is also a good idea to have a variable which can hold a list of all images/batches in your dataset. There are quite a number of things going on in the function we wrote. Let's break it down: \n",
    "\n",
    "- We create two lists `train_data` and `train_labels` to contain the data and their associated labels. This is helpful since we have 5 training batches of 10,000 images each and it will be time consuming to do the same operation over and over again for all 5 batches.\n",
    "\n",
    "- We read in all batches at once in our `for loop`. This is a better approach almost every time and should be applied to any dataset that you're trying to read. \n",
    "\n",
    "- We use a funcion called `np.concatenate` to \"concatenate\" the training data which is in the form of numpy arrays. The labels are in the form of lists and hence we simply use the python concat operator `+` to concatenate them. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `__getitem__` method should accept only one argument: the index of the image/batch you want to access. We get to enjoy our hardwork as we can simply load a data and label by one index and return it. When writing your custom dataloaders it is a good practice to keep your `__getitem__` as simple as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Having written a dataloader, we can now test it. For the time being, don't worry about the test code, we'll get to it in later talks. The code below can be used for testing the dataloader class above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading batch:/home/akulshr/cifar-10-batches-py/data_batch_1\n",
      "Loading batch:/home/akulshr/cifar-10-batches-py/data_batch_2\n",
      "Loading batch:/home/akulshr/cifar-10-batches-py/data_batch_3\n",
      "Loading batch:/home/akulshr/cifar-10-batches-py/data_batch_4\n",
      "Loading batch:/home/akulshr/cifar-10-batches-py/data_batch_5\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfs  = transforms.Compose([transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])# convert any data into a torch tensor\n",
    "\n",
    "root='/home/akulshr/cifar-10-batches-py/'\n",
    "\n",
    "cifar_train = CIFARLoader(root, transform=tfs) # create a \"CIFARLoader instance\".\n",
    "cifar_loader = data.DataLoader(cifar_train, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "data_iter = iter(cifar_loader)\n",
    "data,label = data_iter.next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In our test function we create an \"instance\" of the dataloader. Notice how we don't pass anything to the `target_transform`parameter. This is because our labels in this case are in the form of lists. If they are in a different form then we have to employ different strategies, but this is rare in practice. The output should show you `torch.Size([3,32,32])` which is pytorch way of saying that your data is now a \"tensor\" with dimensions `3x32x32`. This is correct since we know that CIFAR-10 data has dimensions `3x32x32`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ak",
   "language": "python",
   "name": "ak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
