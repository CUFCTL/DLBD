{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pascal VOC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you're going to implement the dataloader for the Pascal-VOC dataset using PyTorch. As introduced in the last talk, Pascal-VOC is a large dataset comprising some 300,000 images which need to be classified into 20 different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin to write a dataloader, we need to get the data in proper directories so that we can access them using our program. Instructions for downloading the PASCAL-VOC dataset can be found [here](https://github.com/CUFCTL/DLBD/wiki/Darknet-on-Palmetto#training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've extracted the dataset and put the data in correct directories, and followed the instructions for genrating the `train.txt` file, you're ready to write dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.utils.data as data \n",
    "\n",
    "#### Pascal-VOC Dataset Loader ##### \n",
    "\n",
    "\n",
    "\n",
    "class VOCLoader(data.Dataset):\n",
    "    \n",
    "    def __init__(self, root, transforms=None):\n",
    "        ####################################################\n",
    "        # As explained in the previous notebook \n",
    "        # this method is used for defining the \n",
    "        # variables that are useful for dataloading\n",
    "        # Here we the following variables :\n",
    "        # root: The 'root' directory of your dataset\n",
    "        # transforms: The 'transforms' that need to be \n",
    "        # done to the dataset before they can be used.\n",
    "        ######################################################\n",
    "        self.root = root \n",
    "        self.transforms = transforms \n",
    "        self.train_f  = os.path.join(self.root, 'train.txt')\n",
    "        self._ids = self._build_dataset(self.train_f)\n",
    "    \n",
    "    \n",
    "    def _build_dataset(self, fname):\n",
    "        ##########################################################\n",
    "        # In order to load a dataset we\n",
    "        # need a list of files which we can\n",
    "        # then load. Notice the self._ids \n",
    "        # variable. This function reads the text file and builds \n",
    "        # the list which is then put in that variable.\n",
    "        ##########################################################\n",
    "        ids = []\n",
    "        ###############################################\n",
    "        #\n",
    "        #             YOUR CODE HERE \n",
    "        #\n",
    "        ###############################################\n",
    "        \n",
    "        return ids \n",
    "    \n",
    "    def _load_labels(self, txt_file):\n",
    "        ####################################################\n",
    "        # When we prepared the data we ran a script which put \n",
    "        # text label files in the \"labels\" directory. In the \n",
    "        # task of image classification we're concerned only with \n",
    "        # the class id of the image. This is the first number in\n",
    "        # every line of the text file. This function takes the\n",
    "        # text file as the argument and returns the number of \n",
    "        # classes and a list containing the classes \n",
    "        #####################################################\n",
    "        lines = [] \n",
    "        ###############################################\n",
    "        #\n",
    "        #             YOUR CODE HERE \n",
    "        #\n",
    "        ###############################################\n",
    "        return len(lines), lines\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #################################################\n",
    "        # Once we have the list of files in the dataset, \n",
    "        # we can then load the data as we want to. In our \n",
    "        # case we are dealing with images and their labels\n",
    "        # we can load images using the function PIL.Image \n",
    "        # The labels will be loaded using the helper function\n",
    "        # you wrote above\n",
    "        ##################################################\n",
    "        im = Image.open(self.ids[index])\n",
    "        length, labels = self._load_labels(self.ids[index])\n",
    "        if self.transforms is not None:\n",
    "            im = self.transforms(im)\n",
    "            labels = self.transforms(labels)\n",
    "        \n",
    "        return im, labels\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once this class is written we can test it out using the following code.  You will need to change the root variable in the following code to make it run correctly. In the last test code we saw how to load `CIFAR-10` data which was a collection of matrices. In Pascal VOC we're dealing with images hence the test code is a little different. The transforms that you see in the test code are essential to the pipeline since they convert any raw data into \"tensors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = transforms.ToTensor()\n",
    "ds = VOCLoader(root, transforms=None)\n",
    "train_loader = data.DataLoader(ds, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "img, labels = data_iter.next()\n",
    "npimg = img.numpy()\n",
    "npimg = npimg.squeeze()\n",
    "npimg = npimg.transpose(2,1,0)\n",
    "plt.imshow(npimg)\n",
    "plt.title('Train Set image')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ak",
   "language": "python",
   "name": "ak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
