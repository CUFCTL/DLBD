{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data is one crucial step in the deep learning pipeline. PyTorch makes it easy to write custom data loaders for your particular dataset. In this notebook, we're going to download and load cifar-10 dataset and return a torch \"tensor\" as the image and the label. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head over to [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset homepage and download the \"python\" version mentioned on the page. Extract the `tar.gz` archive in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 dataset is divided into 5 training batches and one test batch. In order to train effectively we need to use all the training data. The datasets themselves are stored in a \"pickle\" format so we have to \"unpickle\" them first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os \n",
    "import pickle \n",
    "\n",
    "def unpickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        Dict = pickle.load(f, encoding='bytes')\n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if we actually can load the data after the unpickling. For that we're going to load one the data batches and see if we can find the data and labels from it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/akulshr/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78c12489aff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_batch_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3fb3f70026e1>\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/akulshr/data_batch_1'"
     ]
    }
   ],
   "source": [
    "Dic = unpickle(os.path.join(os.getcwd(),'cifar10-data-batches-py', 'data_batch_1'))\n",
    "print(Dic[b'data'].shape)\n",
    "print(Dic[b'labels'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the data is a numpy array of 1000x3072 which means that the data batch contains 10000 images of size 3072 (32x32x3). The labels are 1000x1 list in which the *i*th element corresponds to the correct label for the *i*th image. This is how data is in the other training batches. Whenever you've got a new dataset always try to load one or two images(or a data batch) like in this case to get a feel of how the data is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data like this can be tedious and time consuming. Let's write a helper function which will return the data and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(batch_name):\n",
    "    dic = unpickle(batch_name)\n",
    "    return dic[b'data'], dic[b'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little helper function will call our \"unpickling\" function to unpickle the data and return only the relevant parts of it back to us. While writing dataset loader in general it is helpful to write \"helper\" functions like these to return the data and the label. In datasets where there is only images, you can use `PIL.Image`. Armed with this let's write a dataloader for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch way of doing things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloading in PyTorch is a two step process. First, you need define a custom class which is subclassed from a `data.Dataset` class in `torch.utils.data`. This class takes in arguments which tell PyTorch about the location of the dataset, any \"transforms\" that you need to make before the dataset is loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import the relevant modules. The `data` module which contains the useful functions for dataloading is contained in `torch.utils.data`. We also need a utility called `glob` to get all our batches in a nice list, which we can then index into: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.data.utils as data \n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CIFARLoader(data.Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 Loader: Loads the CIFAR-10 data according to an index value \n",
    "    and returns the data and the labels. \n",
    "    \n",
    "    args:\n",
    "    root: Root of the data directory.\n",
    "    \n",
    "    Optional args:\n",
    "    transforms: The transforms you wish to apply to the data.\n",
    "    target_transforms: The transforms you wish to apply to the labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, root,transform=None, target_transform=None):\n",
    "        self.root = root \n",
    "        self.transform = transform \n",
    "        self.target_transform = target_transform\n",
    "        patt = os.path.join(self.root, 'data_batch_*') # create the pattern we want to search for.\n",
    "        self.batches = sorted(patt) \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch = self.batches[index]\n",
    "        data, labels = load_data(batch)\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform is not None:\n",
    "            labels = self.target_transform(labels)\n",
    "        cache = (data, labels)\n",
    "        return cache\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Every dataloader in PyTorch needs this form. The class you write for a DataLoader contains two methods `__init__` and `__getitem__`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `__init__` method is where you define arguments telling the location of your dataset, transforms (if any). It is also a good idea to have a variable which can hold a list of all images/batches in your dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `__getitem__` method should accept only one argument: the index of the image/batch you want to access. Remember the little helper function we made earlier? We can use that to load our data batch and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Having written a dataloader, we can now test it. For the time being, don't worry about the test code, we'll get to it in later talks. The code below can be used for testing the dataloader class above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "tfs  = transforms.ToTensor() # convert any data into a torch tensor\n",
    "\n",
    "root='/home/akulshr/cifar-10-data-batches-py/'\n",
    "\n",
    "cifar_train = CIFARLoader(root, transforms=tfs, target_transforms=tfs) # create a \"CIFARLoader instance\".\n",
    "cifar_loader = data.DataLoader(cifar_train, batch_size=1, shuffle=True)\n",
    "\n",
    "diter = iter(cifar_loader)\n",
    "cache = diter.next()\n",
    "data, labels = cache \n",
    "print(data.size())\n",
    "print(labels.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ak",
   "language": "python",
   "name": "ak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
